{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e3fcb68",
   "metadata": {},
   "source": [
    "## Script to convert match.json to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb7cea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load JSON data\n",
    "with open('match_9/replay.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare the DataFrame to collect all data\n",
    "columns = ['time', 'player_id', 'kill', 'assist']\n",
    "all_players_data = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Process each player's data\n",
    "for player_key, player_data in data.items():\n",
    "    if player_key.startswith('player_'):\n",
    "        player_id = player_key.split('_')[1]\n",
    "        # Convert kill and assist times to np.array and round them to nearest integer\n",
    "        kill_times = np.round(np.array(player_data['killTimes'])).astype(int)\n",
    "        assist_times = np.round(np.array(player_data['assistTimes'])).astype(int)\n",
    "        \n",
    "        # Determine the max time to cover all slots\n",
    "        max_time = max(np.max(kill_times, initial=0), np.max(assist_times, initial=0))\n",
    "        timeline = np.arange(0, max_time + 1)\n",
    "        \n",
    "        # Initialize kill and assist columns with zeros\n",
    "        kills = np.zeros_like(timeline)\n",
    "        assists = np.zeros_like(timeline)\n",
    "        \n",
    "        # Mark kills and assists at rounded times\n",
    "        for kill_time in kill_times:\n",
    "            if kill_time < len(kills):  # Ensure index is within the array bounds\n",
    "                kills[kill_time] = 1\n",
    "        for assist_time in assist_times:\n",
    "            if assist_time < len(assists):  # Ensure index is within the array bounds\n",
    "                assists[assist_time] = 1\n",
    "        \n",
    "        # Create a DataFrame for the player\n",
    "        player_df = pd.DataFrame({\n",
    "            'time': timeline,\n",
    "            'player_id': player_id,\n",
    "            'kill': kills,\n",
    "            'assist': assists\n",
    "        })\n",
    "        \n",
    "        # Append the player's data to the collective DataFrame\n",
    "        all_players_data = pd.concat([all_players_data, player_df], ignore_index=True)\n",
    "\n",
    "# Sort by player_id first, then by time\n",
    "all_players_data = all_players_data.sort_values(by=['player_id', 'time']).reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "all_players_data.to_csv('match_9.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40ca33b",
   "metadata": {},
   "source": [
    "## Script to merge sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8696f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z0/3x2n2w256hqc2mg2n4y7_0t00000gn/T/ipykernel_83505/4041771514.py:32: FutureWarning: Passing 'suffixes' which cause duplicate columns {'gsr/gsr_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  match_df = match_df.merge(sensor_df, on='time', how='left')\n",
      "/var/folders/z0/3x2n2w256hqc2mg2n4y7_0t00000gn/T/ipykernel_83505/4041771514.py:32: FutureWarning: Passing 'suffixes' which cause duplicate columns {'heart_rate/heart_rate_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  match_df = match_df.merge(sensor_df, on='time', how='left')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the match data\n",
    "match_df = pd.read_csv('match_9.csv')\n",
    "\n",
    "# Ensure the 'time' column is of integer type\n",
    "match_df['time'] = match_df['time'].astype(int)\n",
    "\n",
    "# Define the path to the match_1 directory\n",
    "match_dir = 'match_9'\n",
    "\n",
    "# Placeholder DataFrame to hold combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each player's directory in match_1\n",
    "for player_folder in os.listdir(match_dir):\n",
    "    if player_folder.startswith('player_'):\n",
    "        player_id = player_folder.split('_')[1]\n",
    "        folder_path = os.path.join(match_dir, player_folder)\n",
    "        \n",
    "        # Read and merge sensor data, ensuring the 'time' column is integer type\n",
    "        for sensor_file in ['gsr.csv', 'heart_rate.csv', 'eeg_metrics.csv']:\n",
    "            try:\n",
    "                sensor_df = pd.read_csv(os.path.join(folder_path, sensor_file))\n",
    "                # Ensure the 'time' column in sensor data is of integer type\n",
    "                sensor_df['time'] = sensor_df['time'].astype(int)\n",
    "                # Rename columns to include sensor type for clarity, skipping if it's 'time'\n",
    "                sensor_df.columns = [f\"{sensor_file.split('.')[0]}/{col}\" if col != 'time' else col for col in sensor_df.columns]\n",
    "                # Merge with the match data for this player\n",
    "                match_df = match_df.merge(sensor_df, on='time', how='left')\n",
    "            except FileNotFoundError:\n",
    "                # If a file is not found, it skips without adding its data\n",
    "                pass\n",
    "\n",
    "# Now, filter the match_df for each player and append it to combined_df\n",
    "for player_id in match_df['player_id'].unique():\n",
    "    player_df = match_df[match_df['player_id'] == player_id]\n",
    "    combined_df = pd.concat([combined_df, player_df], ignore_index=True)\n",
    "\n",
    "# Sort by player_id first, then by time\n",
    "combined_df.sort_values(by=['player_id', 'time'], inplace=True)\n",
    "\n",
    "# Save the combined data to a new CSV file\n",
    "combined_df.to_csv('augmented_match_data/match_9_augmented.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016d9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
